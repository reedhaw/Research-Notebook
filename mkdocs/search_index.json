{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Reed Haw's Open Research Notebook!\n\n\nThis website is an open workbook for a Carleton humanities course: \nCrafting Digital History\n. This course focuses on historical data and representation through digital means, as well as using digital technologies to clean, organize, analyze, and represent macrodata (or microdata in a very intricate way).\n\n\nView my GitHub Repository for Digital History \nHere\n\n\nI will be uploading my files for this course into this repository. Check back often to see what's new!\n\n\nThis course is actually all open source. If you want to follow along you can! Because \nCrafting Digital History\n is open source, and you can do all the same exercises that I do, and access all the same resources. If you read something in one of my \nLaboratory\n posts that intrigues you, head over to the \nCrafting Digital History workbook\n, and follow the modules from there! Even if it is just to find out how to install wget or to learn more interesting things like how Markdown works, or even to follow the MkDocs guide that helped me build this notebook! This is all thanks to \nDoctor Shawn Graham\n, who made it all happen.\n\n\nThese sites are still under construction.\n\n\nIt should be noted that both this site, and my other site (\nReed Haw.ca\n) are both under construction still. If you have problems viewing a page or if you notice something wrong, please feel free to \ncontact me\n! I appreciate all feedback. \n\n\nRead up on my work in each module!\n\n\nEvery module written on this website has a corresponding blog post, you can read about it at \nreedhaw.ca/cms/crafting-digital-history\n, and if you want to see the original exercises, you can follow each module heading in the workbook at \nworkbook.craftingdigitalhistory.ca\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-reed-haws-open-research-notebook", 
            "text": "This website is an open workbook for a Carleton humanities course:  Crafting Digital History . This course focuses on historical data and representation through digital means, as well as using digital technologies to clean, organize, analyze, and represent macrodata (or microdata in a very intricate way).", 
            "title": "Welcome to Reed Haw's Open Research Notebook!"
        }, 
        {
            "location": "/#view-my-github-repository-for-digital-history-here", 
            "text": "I will be uploading my files for this course into this repository. Check back often to see what's new!  This course is actually all open source. If you want to follow along you can! Because  Crafting Digital History  is open source, and you can do all the same exercises that I do, and access all the same resources. If you read something in one of my  Laboratory  posts that intrigues you, head over to the  Crafting Digital History workbook , and follow the modules from there! Even if it is just to find out how to install wget or to learn more interesting things like how Markdown works, or even to follow the MkDocs guide that helped me build this notebook! This is all thanks to  Doctor Shawn Graham , who made it all happen.", 
            "title": "View my GitHub Repository for Digital History Here"
        }, 
        {
            "location": "/#these-sites-are-still-under-construction", 
            "text": "It should be noted that both this site, and my other site ( Reed Haw.ca ) are both under construction still. If you have problems viewing a page or if you notice something wrong, please feel free to  contact me ! I appreciate all feedback.", 
            "title": "These sites are still under construction."
        }, 
        {
            "location": "/#read-up-on-my-work-in-each-module", 
            "text": "Every module written on this website has a corresponding blog post, you can read about it at  reedhaw.ca/cms/crafting-digital-history , and if you want to see the original exercises, you can follow each module heading in the workbook at  workbook.craftingdigitalhistory.ca .", 
            "title": "Read up on my work in each module!"
        }, 
        {
            "location": "/hello_world/", 
            "text": "Hello World! (And a brief introduction to me!)\n\n\nHello there! My name is Reed, and I am currently working on a markdown document for the Digital Humanities course at Carleton. The reason I am taking this class is interesting, as it kind of correlates to my direct situation. I am majoring in history at Carleton, currently in my third year, but I think I am going to change my major to one in \nInteractive Multimedia and Design\n. When I found this course I thought it directly correlated to my situation, as I love history, and hope to find a way to intertwine history and technology, much as this course has. This is a terribly big decision for me, but I hope that it all works out in the end. I'm hoping that this gives me an idea of the things I could do if I switched, and the types of things I'd be facing. \n\n\n\n\nThis is one of the biggest decisions in my life, but I truley hope that it is something that I can excell at. I have previously made my own \nwebsite portfolio\n, which showcases some of my accomplishments in the tech world (mostly image editing). I have also taken an \nintroductory computer course\n at Carleton that really opened my eyes to how much I love technology (and yes, admittedly it was a easy, entry level course, but I rocked it). I'm hoping that I can get more invovled in technology here and discover the inner workings of more sophisticated technology. \n\n\n\n\nIn the end, I hope to leave this course with a significantly better understanding of how I can help combine history with technology, whether that is looking at big data or algorithms that can scan archives, I wish no more than to help people see history in a new light. I also hope I learn more about developing webpages and how to display information in a way that is helpful to people, and easy for them to understand (without making it ugly, \nugly websites are the worst\n).", 
            "title": "Hello world"
        }, 
        {
            "location": "/hello_world/#hello-world-and-a-brief-introduction-to-me", 
            "text": "Hello there! My name is Reed, and I am currently working on a markdown document for the Digital Humanities course at Carleton. The reason I am taking this class is interesting, as it kind of correlates to my direct situation. I am majoring in history at Carleton, currently in my third year, but I think I am going to change my major to one in  Interactive Multimedia and Design . When I found this course I thought it directly correlated to my situation, as I love history, and hope to find a way to intertwine history and technology, much as this course has. This is a terribly big decision for me, but I hope that it all works out in the end. I'm hoping that this gives me an idea of the things I could do if I switched, and the types of things I'd be facing.    This is one of the biggest decisions in my life, but I truley hope that it is something that I can excell at. I have previously made my own  website portfolio , which showcases some of my accomplishments in the tech world (mostly image editing). I have also taken an  introductory computer course  at Carleton that really opened my eyes to how much I love technology (and yes, admittedly it was a easy, entry level course, but I rocked it). I'm hoping that I can get more invovled in technology here and discover the inner workings of more sophisticated technology.    In the end, I hope to leave this course with a significantly better understanding of how I can help combine history with technology, whether that is looking at big data or algorithms that can scan archives, I wish no more than to help people see history in a new light. I also hope I learn more about developing webpages and how to display information in a way that is helpful to people, and easy for them to understand (without making it ugly,  ugly websites are the worst ).", 
            "title": "Hello World! (And a brief introduction to me!)"
        }, 
        {
            "location": "/markdown_cheetsheet/", 
            "text": "Copied from [https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet]\n\n\nHeaders\n\n\nH1\n\n\nH2\n\n\nH3\n\n\nH4\n\n\nH5\n\n\nH6\n\n\nAlternatively, for H1 and H2, an underline-ish style:\n\n\nAlt-H1\n\n\nAlt-H2\n\n\nH1\nH2\n\n\nH3\n\n\nH4\n\n\nH5\n\n\nH6\n\n\nAlternatively, for H1 and H2, an underline-ish style:\n\n\nAlt-H1\nAlt-H2\n\n\nEmphasis\n\n\nEmphasis, aka italics, with \nasterisks\n or \nunderscores\n.\n\n\nStrong emphasis, aka bold, with \nasterisks\n or \nunderscores\n.\n\n\nCombined emphasis with \nasterisks and \nunderscores\n.\n\n\nStrikethrough uses two tildes. ~~Scratch this.~~\nEmphasis, aka italics, with asterisks or underscores.\n\n\nStrong emphasis, aka bold, with asterisks or underscores.\n\n\nCombined emphasis with asterisks and underscores.\n\n\nStrikethrough uses two tildes. Scratch this.\n\n\nLists\n\n\n(In this example, leading and trailing spaces are shown with with dots: \u22c5)\n\n\n\n\nFirst ordered list item\n\n\nAnother item\n\u22c5\u22c5* Unordered sub-list. \n\n\nActual numbers don't matter, just that it's a number\n\u22c5\u22c51. Ordered sub-list\n\n\nAnd another item.\n\n\n\n\n\u22c5\u22c5\u22c5You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown).\n\n\n\u22c5\u22c5\u22c5To have a line break without a paragraph, you will need to use two trailing spaces.\u22c5\u22c5\n\u22c5\u22c5\u22c5Note that this line is separate, but within the same paragraph.\u22c5\u22c5\n\u22c5\u22c5\u22c5(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)\n\n\n\n\nUnordered list can use asterisks\n\n\nOr minuses\n\n\nOr pluses\nFirst ordered list item\nAnother item\nUnordered sub-list.\nActual numbers don't matter, just that it's a number\nOrdered sub-list\nAnd another item.\n\n\n\n\nYou can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown).\n\n\nTo have a line break without a paragraph, you will need to use two trailing spaces.\nNote that this line is separate, but within the same paragraph.\n(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)\n\n\nUnordered list can use asterisks\nOr minuses\nOr pluses\n\n\nLinks\n\n\nThere are two ways to create links.\n\n\nI'm an inline-style link\n\n\nI'm an inline-style link with title\n\n\nI'm a reference-style link\n\n\nI'm a relative reference to a repository file\n\n\nYou can use numbers for reference-style link definitions\n\n\nOr leave it empty and use the \nlink text itself\n.\n\n\nURLs and URLs in angle brackets will automatically get turned into links. \nhttp://www.example.com or \nhttp://www.example.com\n and sometimes \nexample.com (but not on Github, for example).\n\n\nSome text to show that the reference links can follow later.\n\n\nI'm an inline-style link\n\n\nI'm an inline-style link with title\n\n\nI'm a reference-style link\n\n\nI'm a relative reference to a repository file\n\n\nYou can use numbers for reference-style link definitions\n\n\nOr leave it empty and use the link text itself.\n\n\nURLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example).\n\n\nSome text to show that the reference links can follow later.\n\n\nImages\n\n\nHere's our logo (hover to see the title text):\n\n\nInline-style: \n\n\n\nReference-style: \n\n\n\nHere's our logo (hover to see the title text):\n\n\nInline-style:  alt text\n\n\nReference-style:  alt text\n\n\nCode and Syntax Highlighting\n\n\nCode blocks are part of the Markdown spec, but syntax highlighting isn't. However, many renderers -- like Github's and Markdown Here -- support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. Markdown Here supports highlighting for dozens of languages (and not-really-languages, like diffs and HTTP headers); to see the complete list, and how to write the language names, see the highlight.js demo page.\n\n\nInline \ncode\n has \nback-ticks around\n it.\nInline code has back-ticks around it.\n\n\nBlocks of code are either fenced by lines with three back-ticks ```, or are indented with four spaces. I recommend only using the fenced code blocks -- they're easier and only they support syntax highlighting.\n\n\nvar s = \nJavaScript syntax highlighting\n;\nalert(s);\n\n\n\n\ns = \nPython syntax highlighting\n\nprint s\n\n\n\n\nNo language indicated, so no syntax highlighting. \nBut let's throw in a \nb\ntag\n/b\n.\n\n\n\n\nvar s = \"JavaScript syntax highlighting\";\nalert(s);\ns = \"Python syntax highlighting\"\nprint s\nNo language indicated, so no syntax highlighting in Markdown Here (varies on Github). \nBut let's throw in a \ntag\n.\n\n\nTables\n\n\nTables aren't part of the core Markdown spec, but they are part of GFM and Markdown Here supports them. They are an easy way of adding tables to your email -- a task that would otherwise require copy-pasting from another application.\n\n\nColons can be used to align columns.\n\n\n\n\n\n\n\n\nTables\n\n\nAre\n\n\nCool\n\n\n\n\n\n\n\n\n\n\ncol 3 is\n\n\nright-aligned\n\n\n$1600\n\n\n\n\n\n\ncol 2 is\n\n\ncentered\n\n\n$12\n\n\n\n\n\n\nzebra stripes\n\n\nare neat\n\n\n$1\n\n\n\n\n\n\n\n\nThere must be at least 3 dashes separating each header cell.\nThe outer pipes (|) are optional, and you don't need to make the \nraw Markdown line up prettily. You can also use inline Markdown.\n\n\n\n\n\n\n\n\nMarkdown\n\n\nLess\n\n\nPretty\n\n\n\n\n\n\n\n\n\n\nStill\n\n\nrenders\n\n\nnicely\n\n\n\n\n\n\n1\n\n\n2\n\n\n3\n\n\n\n\n\n\nColons can be used to align columns.\n\n\n\n\n\n\n\n\n\n\n\n\nTables  Are Cool\ncol 3 is    right-aligned   $1600\ncol 2 is    centered    $12\nzebra stripes   are neat    $1\nThere must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown.\n\n\nMarkdown    Less    Pretty\nStill   renders nicely\n1   2   3\n\n\nBlockquotes\n\n\n\n\nBlockquotes are very handy in email to emulate reply text.\nThis line is part of the same quote.\n\n\n\n\nQuote break.\n\n\n\n\nThis is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can \nput\n \nMarkdown\n into a blockquote. \nBlockquotes are very handy in email to emulate reply text. This line is part of the same quote.\nQuote break.\n\n\n\n\nThis is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote.\n\n\nInline HTML\n\n\nYou can also use raw HTML in your Markdown, and it'll mostly work pretty well.\n\n\n\n  \nDefinition list\n\n  \nIs something people use sometimes.\n\n\n  \nMarkdown in HTML\n\n  \nDoes *not* work **very** well. Use HTML \ntags\n.\n\n\n\n\n\nDefinition list\nIs something people use sometimes.\nMarkdown in HTML\nDoes \nnot\n work \nvery\n well. Use HTML tags.\n\n\nHorizontal Rule\n\n\nThree or more...\n\n\n\n\nHyphens\n\n\n\n\nAsterisks\n\n\n\n\nUnderscores\nThree or more...\n\n\nHyphens\n\n\nAsterisks\n\n\nUnderscores\n\n\nLine Breaks\n\n\nMy basic recommendation for learning how line breaks work is to experiment and discover -- hit \n once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You'll soon learn to get what you want. \"Markdown Toggle\" is your friend.\n\n\nHere are some things to try out:\n\n\nHere's a line for us to start with.\n\n\nThis line is separated from the one above by two newlines, so it will be a \nseparate paragraph\n.\n\n\nThis line is also a separate paragraph, but...\nThis line is only separated by a single newline, so it's a separate line in the \nsame paragraph\n.\nHere's a line for us to start with.\n\n\nThis line is separated from the one above by two newlines, so it will be a separate paragraph.\n\n\nThis line is also begins a separate paragraph, but...\nThis line is only separated by a single newline, so it's a separate line in the same paragraph.\n\n\n(Technical note: Markdown Here uses GFM line breaks, so there's no need to use MD's two-space line breaks.)\n\n\nYoutube videos\n\n\nThey can't be added directly but you can add an image with a link to the video like this:\n\n\n\nOr, in pure Markdown, but losing the image sizing and border:\n\n\n\nReferencing a bug by #bugID in your git commit links it to the slip. For example #1.\nStatus API Training Shop Blog About Pricing\n\u00a9 2016 GitHub, Inc. Terms Privacy Security Contact Help", 
            "title": "Markdown cheetsheet"
        }, 
        {
            "location": "/markdown_cheetsheet/#h1", 
            "text": "", 
            "title": "H1"
        }, 
        {
            "location": "/markdown_cheetsheet/#h2", 
            "text": "", 
            "title": "H2"
        }, 
        {
            "location": "/markdown_cheetsheet/#h3", 
            "text": "", 
            "title": "H3"
        }, 
        {
            "location": "/markdown_cheetsheet/#h4", 
            "text": "", 
            "title": "H4"
        }, 
        {
            "location": "/markdown_cheetsheet/#h5", 
            "text": "", 
            "title": "H5"
        }, 
        {
            "location": "/markdown_cheetsheet/#h6", 
            "text": "Alternatively, for H1 and H2, an underline-ish style:", 
            "title": "H6"
        }, 
        {
            "location": "/markdown_cheetsheet/#alt-h1", 
            "text": "", 
            "title": "Alt-H1"
        }, 
        {
            "location": "/markdown_cheetsheet/#alt-h2", 
            "text": "H1\nH2  H3  H4  H5  H6  Alternatively, for H1 and H2, an underline-ish style:  Alt-H1\nAlt-H2  Emphasis  Emphasis, aka italics, with  asterisks  or  underscores .  Strong emphasis, aka bold, with  asterisks  or  underscores .  Combined emphasis with  asterisks and  underscores .  Strikethrough uses two tildes. ~~Scratch this.~~\nEmphasis, aka italics, with asterisks or underscores.  Strong emphasis, aka bold, with asterisks or underscores.  Combined emphasis with asterisks and underscores.  Strikethrough uses two tildes. Scratch this.  Lists  (In this example, leading and trailing spaces are shown with with dots: \u22c5)   First ordered list item  Another item\n\u22c5\u22c5* Unordered sub-list.   Actual numbers don't matter, just that it's a number\n\u22c5\u22c51. Ordered sub-list  And another item.   \u22c5\u22c5\u22c5You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown).  \u22c5\u22c5\u22c5To have a line break without a paragraph, you will need to use two trailing spaces.\u22c5\u22c5\n\u22c5\u22c5\u22c5Note that this line is separate, but within the same paragraph.\u22c5\u22c5\n\u22c5\u22c5\u22c5(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)   Unordered list can use asterisks  Or minuses  Or pluses\nFirst ordered list item\nAnother item\nUnordered sub-list.\nActual numbers don't matter, just that it's a number\nOrdered sub-list\nAnd another item.   You can have properly indented paragraphs within list items. Notice the blank line above, and the leading spaces (at least one, but we'll use three here to also align the raw Markdown).  To have a line break without a paragraph, you will need to use two trailing spaces.\nNote that this line is separate, but within the same paragraph.\n(This is contrary to the typical GFM line break behaviour, where trailing spaces are not required.)  Unordered list can use asterisks\nOr minuses\nOr pluses  Links  There are two ways to create links.  I'm an inline-style link  I'm an inline-style link with title  I'm a reference-style link  I'm a relative reference to a repository file  You can use numbers for reference-style link definitions  Or leave it empty and use the  link text itself .  URLs and URLs in angle brackets will automatically get turned into links. \nhttp://www.example.com or  http://www.example.com  and sometimes \nexample.com (but not on Github, for example).  Some text to show that the reference links can follow later.  I'm an inline-style link  I'm an inline-style link with title  I'm a reference-style link  I'm a relative reference to a repository file  You can use numbers for reference-style link definitions  Or leave it empty and use the link text itself.  URLs and URLs in angle brackets will automatically get turned into links. http://www.example.com or http://www.example.com and sometimes example.com (but not on Github, for example).  Some text to show that the reference links can follow later.  Images  Here's our logo (hover to see the title text):  Inline-style:   Reference-style:   Here's our logo (hover to see the title text):  Inline-style:  alt text  Reference-style:  alt text  Code and Syntax Highlighting  Code blocks are part of the Markdown spec, but syntax highlighting isn't. However, many renderers -- like Github's and Markdown Here -- support syntax highlighting. Which languages are supported and how those language names should be written will vary from renderer to renderer. Markdown Here supports highlighting for dozens of languages (and not-really-languages, like diffs and HTTP headers); to see the complete list, and how to write the language names, see the highlight.js demo page.  Inline  code  has  back-ticks around  it.\nInline code has back-ticks around it.  Blocks of code are either fenced by lines with three back-ticks ```, or are indented with four spaces. I recommend only using the fenced code blocks -- they're easier and only they support syntax highlighting.  var s =  JavaScript syntax highlighting ;\nalert(s);  s =  Python syntax highlighting \nprint s  No language indicated, so no syntax highlighting. \nBut let's throw in a  b tag /b .  var s = \"JavaScript syntax highlighting\";\nalert(s);\ns = \"Python syntax highlighting\"\nprint s\nNo language indicated, so no syntax highlighting in Markdown Here (varies on Github). \nBut let's throw in a  tag .  Tables  Tables aren't part of the core Markdown spec, but they are part of GFM and Markdown Here supports them. They are an easy way of adding tables to your email -- a task that would otherwise require copy-pasting from another application.  Colons can be used to align columns.     Tables  Are  Cool      col 3 is  right-aligned  $1600    col 2 is  centered  $12    zebra stripes  are neat  $1     There must be at least 3 dashes separating each header cell.\nThe outer pipes (|) are optional, and you don't need to make the \nraw Markdown line up prettily. You can also use inline Markdown.     Markdown  Less  Pretty      Still  renders  nicely    1  2  3    Colons can be used to align columns.       Tables  Are Cool\ncol 3 is    right-aligned   $1600\ncol 2 is    centered    $12\nzebra stripes   are neat    $1\nThere must be at least 3 dashes separating each header cell. The outer pipes (|) are optional, and you don't need to make the raw Markdown line up prettily. You can also use inline Markdown.  Markdown    Less    Pretty\nStill   renders nicely\n1   2   3  Blockquotes   Blockquotes are very handy in email to emulate reply text.\nThis line is part of the same quote.   Quote break.   This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can  put   Markdown  into a blockquote. \nBlockquotes are very handy in email to emulate reply text. This line is part of the same quote.\nQuote break.   This is a very long line that will still be quoted properly when it wraps. Oh boy let's keep writing to make sure this is long enough to actually wrap for everyone. Oh, you can put Markdown into a blockquote.  Inline HTML  You can also use raw HTML in your Markdown, and it'll mostly work pretty well.  \n   Definition list \n   Is something people use sometimes. \n\n   Markdown in HTML \n   Does *not* work **very** well. Use HTML  tags .   Definition list\nIs something people use sometimes.\nMarkdown in HTML\nDoes  not  work  very  well. Use HTML tags.  Horizontal Rule  Three or more...   Hyphens   Asterisks   Underscores\nThree or more...  Hyphens  Asterisks  Underscores  Line Breaks  My basic recommendation for learning how line breaks work is to experiment and discover -- hit   once (i.e., insert one newline), then hit it twice (i.e., insert two newlines), see what happens. You'll soon learn to get what you want. \"Markdown Toggle\" is your friend.  Here are some things to try out:  Here's a line for us to start with.  This line is separated from the one above by two newlines, so it will be a  separate paragraph .  This line is also a separate paragraph, but...\nThis line is only separated by a single newline, so it's a separate line in the  same paragraph .\nHere's a line for us to start with.  This line is separated from the one above by two newlines, so it will be a separate paragraph.  This line is also begins a separate paragraph, but...\nThis line is only separated by a single newline, so it's a separate line in the same paragraph.  (Technical note: Markdown Here uses GFM line breaks, so there's no need to use MD's two-space line breaks.)  Youtube videos  They can't be added directly but you can add an image with a link to the video like this:  \nOr, in pure Markdown, but losing the image sizing and border:  \nReferencing a bug by #bugID in your git commit links it to the slip. For example #1.\nStatus API Training Shop Blog About Pricing\n\u00a9 2016 GitHub, Inc. Terms Privacy Security Contact Help", 
            "title": "Alt-H2"
        }, 
        {
            "location": "/Module_2/", 
            "text": "Module 2\n\n\n2/16/2016 8:37:25 PM \n\n\nExercise 1\n\n\nI did a search for my surname (Haw) in the memorial database, and found no casualties reported in the war. Now I do know this is accurate (on the Canadian side) as all the members in my family that fought in the war survived. However, upon doing a search for Haw in England, I found four servicemen that died in the Wars, and they all appeared to be from the same family (John and Richard were both common names among the four). \n\n\nExercise 2\n\n\nUsing Outwit Hub I imported the contents of the search for \"pie\" on [http://www.stoa.org/]. Scraping the HTML from the search page allowed me to view the elements that are invisible behind the CSS of the page (mostly). I've added a few lines of the table below:\n\n\n\n\n\n\n\n\nCollection Time\n\n\nSource URL\n\n\nTranscription\n\n\n\n\n\n\n\n\n\n\n2/16/2016 6:26:16 PM\n\n\nhttp://www.stoa.org/sol-bin/search.pl\n\n\nMeaning you will depart. Sophocles [sc. uses the word].\n\n\n\n\n\n\n2/16/2016 6:26:16 PM\n\n\nhttp://www.stoa.org/sol-bin/search.pl\n\n\n[Meaning] to the ground, into/towards [the] earth. Also [sc. attested is] \u03c7\u03b1\u03bc\u1fb6\u03b6\u03b5, [also meaning] to the ground.\n\n\n\n\n\n\n2/16/2016 6:26:16 PM\n\n\nhttp://www.stoa.org/sol-bin/search.pl\n\n\n[The words] \u03c7\u03bb\u03bf\u03b5\u03c1\u1f79\u03c2 and \u03c7\u03bb\u03c9\u03c1\u1f79\u03c2 [\"pale green\"] [are derived] from \u03c7\u03bf\u03bb\u1f75 [\"bile\"], and from this the [word] \u1f60\u03c7\u03c1\u1f79\u03c2 [\"sallow\"] [also comes]. And [sc. also attested is] \u03c7\u03bb\u03c9\u03c1\u1f79\u03c4\u03b7\u03c2 [\"greenness\"].\n\n\n\n\n\n\n\n\nThis information can be valuable when looking at large allotments of information. A search can only give you one or two things at a time, but by using software such as Outwit Hub, I am able to capture multiple pieces of data at a time from a web page, including source URL, date and the captured text. By modifying the search parameters, one could easily use Outwit hub to quickly capture large amounts of search data, and by compiling into a spreadsheet it allows for  easy viewing and visualization of the important information, as well as the ability to create data charts and graphs. Ultimately it would be one of the easiest ways to gather information. The ability to see a compilation of what is written in the page gives a powerful overview, which is especially important in research. \n\n\nExercise 3\n\n\nThis section of the module was one I was nervous to begin. I was told that it was going to be a difficult section, especially for Windows users (which, of course, I am one). But entering this Exercise I didn't find it as difficult as I had anticipated. Most of the stuff that is typically unused by other people, but editing the \npath\n variable under system environments to include CoreUtils and installing wget through chocolatey are all things that I had previously had to deal with. My previous experience working with these advanced settings and programs made it significantly easier to work with the Canadiana JSON program. I used the search for articles and pieces on the Titanic written between 1910 and 1916, and with the program I was able to download these articles onto my computer. One thing I noticed is the first two tests I ran of the program it was able to recognize and work properly, but I was getting the error that wget was an \nuknown command\n, so I had to figure out how to properly install wget. I realized I could use chocolatey in either Git Bash or command prompt to download and install the program (chocolatey is now one of my favourite programs). After successfully installing this, I got my \noutput.txt\n file, and the only thing that remained was to split it up. I tried running \nsplitthingsup.sh\n but it gave my over 24,000 files that mostly had 1 kb of data for each containing next to nothing. So I tried the code \nawk '/identifier/{\"F\"++i;}{print \n \"newoutput\"i\".txt\";}' output.txt\n written by Lee Mordechai, and it worked significantly better, leaving me with 204 files. Much more manageable. I might even take a look to see if I can divide it up split it up with my own identifiers. \n\n\nExercise 4\n\n\nThis exercise was more of a developmental/eyeopening thing for most people I think. Backing up and redundancies is probably one of my favourite things to do. I am a firm believer that things need to be backed up on a regular basis. I have my phone backing up to a cloud daily, and my computer backing up to an external drive every hour. I hope to set up NAS (network attached storage) server using an old computer, because I'm weirdly paranoid about that. So reading Donna Yates redundancies made me excessively happy. Although I don't have three external hard drives, I love the way Yates does this backup, and all of the redundancies to ensure that they will never be lost. I can see the paranoia behind the failing URLs and the slight possibility of corrupting the PDFs, I would likely not have quite so many redundancies as that, but I also am not writing academic articles for my career, but if I was I would likely do the same. \n\n\nNow, if I were to do the same from now on, I would likely create a folder for the paper and save the PDFs there, and create a backup on my external. However, I have never used BibDesk before, but I am definitely going to try it, and if I like it I will definitely use it. And when it comes to me and filling in fields, I have to complete them all. \n\n\nGoing Further: Wget\n\n\nSo Wget is one of those things that I think would be very VERY useful. And I basically have a handle on it. I managed to get it to mostly work at downloading the archives.org articles, but my biggest problem was it was originally saying there was an error unable to resolve the host in regards to the options for wget, aka a \n-i\n or \n-e robots=off\n, so I went to the Wget cheat sheet and read through all of it. In it I was able to see what each command was and tried playing around with a few things. After a while I finally got the program to start grabbing things, but then I was getting \nError ... 404 not found\n, so upon inspection I noticed that Wget was adding %22 to each one of my URLs, so something was wrong there with my text file. Unfortunately I don't quite have time to look into it too deeply at the moment, but when I do have troubles with Wget in the future, I at least have an idea at what I need to look at to find the problem. It is definitely one of my favourite tools so far though.", 
            "title": "Module 2"
        }, 
        {
            "location": "/Module_2/#module-2", 
            "text": "2/16/2016 8:37:25 PM", 
            "title": "Module 2"
        }, 
        {
            "location": "/Module_2/#exercise-1", 
            "text": "I did a search for my surname (Haw) in the memorial database, and found no casualties reported in the war. Now I do know this is accurate (on the Canadian side) as all the members in my family that fought in the war survived. However, upon doing a search for Haw in England, I found four servicemen that died in the Wars, and they all appeared to be from the same family (John and Richard were both common names among the four).", 
            "title": "Exercise 1"
        }, 
        {
            "location": "/Module_2/#exercise-2", 
            "text": "Using Outwit Hub I imported the contents of the search for \"pie\" on [http://www.stoa.org/]. Scraping the HTML from the search page allowed me to view the elements that are invisible behind the CSS of the page (mostly). I've added a few lines of the table below:     Collection Time  Source URL  Transcription      2/16/2016 6:26:16 PM  http://www.stoa.org/sol-bin/search.pl  Meaning you will depart. Sophocles [sc. uses the word].    2/16/2016 6:26:16 PM  http://www.stoa.org/sol-bin/search.pl  [Meaning] to the ground, into/towards [the] earth. Also [sc. attested is] \u03c7\u03b1\u03bc\u1fb6\u03b6\u03b5, [also meaning] to the ground.    2/16/2016 6:26:16 PM  http://www.stoa.org/sol-bin/search.pl  [The words] \u03c7\u03bb\u03bf\u03b5\u03c1\u1f79\u03c2 and \u03c7\u03bb\u03c9\u03c1\u1f79\u03c2 [\"pale green\"] [are derived] from \u03c7\u03bf\u03bb\u1f75 [\"bile\"], and from this the [word] \u1f60\u03c7\u03c1\u1f79\u03c2 [\"sallow\"] [also comes]. And [sc. also attested is] \u03c7\u03bb\u03c9\u03c1\u1f79\u03c4\u03b7\u03c2 [\"greenness\"].     This information can be valuable when looking at large allotments of information. A search can only give you one or two things at a time, but by using software such as Outwit Hub, I am able to capture multiple pieces of data at a time from a web page, including source URL, date and the captured text. By modifying the search parameters, one could easily use Outwit hub to quickly capture large amounts of search data, and by compiling into a spreadsheet it allows for  easy viewing and visualization of the important information, as well as the ability to create data charts and graphs. Ultimately it would be one of the easiest ways to gather information. The ability to see a compilation of what is written in the page gives a powerful overview, which is especially important in research.", 
            "title": "Exercise 2"
        }, 
        {
            "location": "/Module_2/#exercise-3", 
            "text": "This section of the module was one I was nervous to begin. I was told that it was going to be a difficult section, especially for Windows users (which, of course, I am one). But entering this Exercise I didn't find it as difficult as I had anticipated. Most of the stuff that is typically unused by other people, but editing the  path  variable under system environments to include CoreUtils and installing wget through chocolatey are all things that I had previously had to deal with. My previous experience working with these advanced settings and programs made it significantly easier to work with the Canadiana JSON program. I used the search for articles and pieces on the Titanic written between 1910 and 1916, and with the program I was able to download these articles onto my computer. One thing I noticed is the first two tests I ran of the program it was able to recognize and work properly, but I was getting the error that wget was an  uknown command , so I had to figure out how to properly install wget. I realized I could use chocolatey in either Git Bash or command prompt to download and install the program (chocolatey is now one of my favourite programs). After successfully installing this, I got my  output.txt  file, and the only thing that remained was to split it up. I tried running  splitthingsup.sh  but it gave my over 24,000 files that mostly had 1 kb of data for each containing next to nothing. So I tried the code  awk '/identifier/{\"F\"++i;}{print   \"newoutput\"i\".txt\";}' output.txt  written by Lee Mordechai, and it worked significantly better, leaving me with 204 files. Much more manageable. I might even take a look to see if I can divide it up split it up with my own identifiers.", 
            "title": "Exercise 3"
        }, 
        {
            "location": "/Module_2/#exercise-4", 
            "text": "This exercise was more of a developmental/eyeopening thing for most people I think. Backing up and redundancies is probably one of my favourite things to do. I am a firm believer that things need to be backed up on a regular basis. I have my phone backing up to a cloud daily, and my computer backing up to an external drive every hour. I hope to set up NAS (network attached storage) server using an old computer, because I'm weirdly paranoid about that. So reading Donna Yates redundancies made me excessively happy. Although I don't have three external hard drives, I love the way Yates does this backup, and all of the redundancies to ensure that they will never be lost. I can see the paranoia behind the failing URLs and the slight possibility of corrupting the PDFs, I would likely not have quite so many redundancies as that, but I also am not writing academic articles for my career, but if I was I would likely do the same.   Now, if I were to do the same from now on, I would likely create a folder for the paper and save the PDFs there, and create a backup on my external. However, I have never used BibDesk before, but I am definitely going to try it, and if I like it I will definitely use it. And when it comes to me and filling in fields, I have to complete them all.", 
            "title": "Exercise 4"
        }, 
        {
            "location": "/Module_2/#going-further-wget", 
            "text": "So Wget is one of those things that I think would be very VERY useful. And I basically have a handle on it. I managed to get it to mostly work at downloading the archives.org articles, but my biggest problem was it was originally saying there was an error unable to resolve the host in regards to the options for wget, aka a  -i  or  -e robots=off , so I went to the Wget cheat sheet and read through all of it. In it I was able to see what each command was and tried playing around with a few things. After a while I finally got the program to start grabbing things, but then I was getting  Error ... 404 not found , so upon inspection I noticed that Wget was adding %22 to each one of my URLs, so something was wrong there with my text file. Unfortunately I don't quite have time to look into it too deeply at the moment, but when I do have troubles with Wget in the future, I at least have an idea at what I need to look at to find the problem. It is definitely one of my favourite tools so far though.", 
            "title": "Going Further: Wget"
        }, 
        {
            "location": "/Module_3/", 
            "text": "Module 3\n\n\n3/19/2016 1:16:47 PM \n\n\nText Encoding\n\n\nRecovered Histories\n Vetting\n\n\nNegatives:\n\n\n\n\nSite is \"Lottery Funded\", and does not appear to be affiliated with an academic institution\n\n\nWebsites design and style is outdated, which creates possibility that all the information is outdated, or not to modern standards \n\n\nDoes not have any outside links or sources, other than what is presented in its collection \n\n\nA significant portion of the literature in the collection appears to be from slavers and free white men\n\n\nSome items in collection have very messy handwriting, making it more difficult to encode the information and recognize characters \n\n\n\n\nPositives:\n\n\n\n\nSite is \"Lottery Funded\", which can be viewed in a positive way, as it prevents people from becoming biased or for altering information to help prove their point\n\n\nEncourages users to generate own content using site as raw resource\n\n\nAppears to reference information in its collection by linking to the specific articles\n\n\nDocuments in collection are scanned and then uploaded, they are not transcribed, which can cause differences\n\n\nSearch tool provides what appears to be accurate reading of the collection\n\n\n\n\nTranscription\n\n\nThe transcription went smoothly at first. Upon entering my first tags, I tested it in Internet Explorer and got the colourfully transcribed version of \nNegro Slavery by Zachary MacAulay\n. But then I went back and added some a few more place and name tags, and the text disappeared. I had the paragraphs separated and encased in tags, rather than inline tags, and I think that's where my problem came from. For example:\n\n\nAfter going through each paragraph break, I managed to get proper formatting back, with colours. My suspicion is that one of my location tags got separated when I was spacing out the text. A simple mistake.  \n\n\nTransformations\n\n\nIn my page5.xml file, the xsl styling is looking for tags like \npersName\n and \ninterp\n. These titles point the browser to the same tag in the .xsl document which defines the style of the .xml file. This uses the same system that web pages utilize, the HTML pointing the browser to the styles defined in the CSS document. \n\n\nIn \nSG_transformer.xsl\n, the browser will be looking at tags such as \nID\n, or \nRepository\n. I \nbelieve\n this uses an elif system, where it defines a list of words as the root of the tag, and each tag would receive a value-of, which might give a tooltip? I'm not 100% on the appearance of the .xml page once these tags are used. \n\n\nTo define different .xsl sheets, you would change the \nhref\n designation on line 2 from: \n?cml-stylesheet type=\"text/xsl\" href=\"000stylesheet.xsl\"?\n to \n?cml-stylesheet type=\"text/xsl\" href=\"SG_transformer.xsl\"?\n. I tried this and didn't get any change in my own .xml file, but I believe that is 1. because I don't have any of the tags and 2. because the \nSG_transformer.xsl\n file does not have any defined template styles in it. I compared it to the 000style.xsl and the colours and appearance of the tags are defined under the \nstyle\n tag throughout the document, which \nSG_transformer.xsl\n is lacking. \n\n\nIf you want to see the pages, you can view my transcription \nhere\n. I also apologize for putting the transformer.xsl file as code, the underscore in it was italicizing large swathes of my text that happened to fall between them. \n\n\nRegex\n\n\nAfter reading the gentle introduction, I can understand how powerful it can be once one knows how to use it. It's a good thing I made a copy. I also need to be careful as to where I leave my cursor when I'm searching. When I leave it at the end, it's hard to find anything in the document after it. \n\n\n\\r\\n\n did not work to find the blank lines. To remove the white spaces, I went into \nRegExr's Cheatsheet\n and found the Regex for word, which was \n\\w\n, and then used \n\\r\\n[^\\w].+\n to find all of the white spaces in my document to remove. It successfully worked, however it did leave a few large chunks with blank lines that I can't get RegEx to clear. I suspect that it is because there was more than one line with it, and when I replaced the previous characters with the the empty replace bar, it replaced everything, but maybe put in an invisible character I can't see. I'm not sure yet, still trying. For the sake of my sanity I had to go through and remove each chunk by hand. It wasn't difficult though, as there were only twelve or so of these chunks. I think it's where \"Digitized By Google\" used to sit in the document, and they may have put in something that my text editor can't see/copy. Still not sure.  \n\n\nI find that \nRegExr\n doesn't seem to process my work properly. I'm not sure why, but I actually find it relatively easy to use Notepad++ as it displays a window at the bottom of the document with all of the information that the find function works. And if something doesn't work, ctrl+Z works magical wonders. \n\n\nWhile trying to replace the page number and comma at the end of each index entry, I was getting very bizarre numbers at the end of the entry. Until I realized I had put the space in the wrong spot. When replacing \n(, )([0-9]{4})(.+)\n with \n\\2\n I was getting an entry that looked like this: \n\n~Sam Houston to J. Pinckney Henderson, December 311836\n\nThen I realized my misplaced space was in the wrong group, and found that \n(,)( [0-9]{4})(.+)\n worked significantly better. I proceeded to have a moment of panic when I noticed lines like this: \n\nDavid G. Bumet, Alc6e La Branche, December 16, 1839 61\nDavid G. Bumet, Alc^ La Branche, December 17, 1839 63\n\nBut then upon checking the original document, that is what Google's OCR thought the characters represented.\n\n\nSomething messed up my saves and I managed to save over my step 5 with an earlier version, so I have to backtrack a bit to get back on track, and redo step five and six. In the midst of finding this, I realized I had left the dates at the ends of each entry, so every search would come up with more than three commas in each sentence. So backtrack a little further to step 4. And I managed to fix it with the given Regex. I'm not a hundred percent on what made that occur. \n\n\nOpen Refine\n\n\nInteresting tool. I worked through it all only to find that it left a few entries (possibly worse off). I think its because I might have been trying to add an accented e, but it didn't like it, as a few of my entries have an @ sign in it randomly that wasn't there before. I might try running it through again later, but at least I now know how to basically work the program (which is awesome). Just to play with it, I'm now uploading my .csv into Palladio to see what it comes up with. Data visualization is one of my favourite things! \n\n\nI don't quite understand it at the moment. Maybe I'll come back to it. \n\n\nStanford NER\n\n\nSo I'm having significant issues with this one. I can't seem to run the \nner-gui.bat\n file to run, it opens a window only to immediately close it again. So following the directions on the end of the Open Refine page, I attempted to run it from the command line in the folder and I'm getting an exception in thread, but I can't figure out what I've done wrong. I have a feeling its something to do with a missing Java definition. I think it's specifically struggling with \nedu.stanford.nlp.ie.crf.CRFClassifier\n  \n\n\nI figured it out. The problem was that I've been trying to run it from command line with the text from the \nworkbook\n, which wasn't working. So I tried updating Java, and did that successfully. Still nothing. I was able to successfully open a gui using \nstanford-ner.jar\n, but when I put the text in and selected a classifier, it was not doing anything. So I deleted a large selection of it and finally got my results! \n\n\nIt highlighted my text like it was supposed to. But now the problem remains that I don't have all of the text classified, which I think is going to be a problem in the next exercise. I have a suspicion that the problem is that my computer isn't allocating enough memory, which the Stanford NER page says is a problem: \n\n\n\n\nIt might work to double-click on the stanford-ner.jar archive but this may well fail as the operating system does not give Java enough memory for our NER system, so it is safer to instead double click on the ner-gui.bat icon (Windows) or ner-gui.sh (Linux/Unix/MacOSX).\n\n\n\n\nI tried increasing the amount of memory Java gets by default, it did not work either. So now I'm going to try and run only half the file. If that works, I'll save the single file into two files, run each one individually, then amalgamate the two after. I know it doesn't exactly fix my issues long term but it is a working solution. \n\n\nSuccess with half the document! I've broken it into two individual files now to run through the NER gui.\n\n\nUpdate:\n\nThe splitting didn't work, it tagged the files but it only highlighted it in the gui. So I went back and edited the \nner-gui.bat\n file, adding a \npause\n function so I could read what the command file without it auto-quitting, I discovered it was having giving an \nunable to allocate space\n. SO I went into the .bat file and messed around with the \nJava -mx\n size, and found that it worked successfully, and I could run file through the gui and successfully save a tagged version of the file (which I couldn't do before). \n\n\nThe tagged Texas letters can be found \nhere\n.\n\n\nAnd the index can be found \nhere\n.", 
            "title": "Module 3"
        }, 
        {
            "location": "/Module_3/#module-3", 
            "text": "3/19/2016 1:16:47 PM", 
            "title": "Module 3"
        }, 
        {
            "location": "/Module_3/#text-encoding", 
            "text": "", 
            "title": "Text Encoding"
        }, 
        {
            "location": "/Module_3/#recovered-histories-vetting", 
            "text": "", 
            "title": "Recovered Histories Vetting"
        }, 
        {
            "location": "/Module_3/#negatives", 
            "text": "Site is \"Lottery Funded\", and does not appear to be affiliated with an academic institution  Websites design and style is outdated, which creates possibility that all the information is outdated, or not to modern standards   Does not have any outside links or sources, other than what is presented in its collection   A significant portion of the literature in the collection appears to be from slavers and free white men  Some items in collection have very messy handwriting, making it more difficult to encode the information and recognize characters", 
            "title": "Negatives:"
        }, 
        {
            "location": "/Module_3/#positives", 
            "text": "Site is \"Lottery Funded\", which can be viewed in a positive way, as it prevents people from becoming biased or for altering information to help prove their point  Encourages users to generate own content using site as raw resource  Appears to reference information in its collection by linking to the specific articles  Documents in collection are scanned and then uploaded, they are not transcribed, which can cause differences  Search tool provides what appears to be accurate reading of the collection", 
            "title": "Positives:"
        }, 
        {
            "location": "/Module_3/#transcription", 
            "text": "The transcription went smoothly at first. Upon entering my first tags, I tested it in Internet Explorer and got the colourfully transcribed version of  Negro Slavery by Zachary MacAulay . But then I went back and added some a few more place and name tags, and the text disappeared. I had the paragraphs separated and encased in tags, rather than inline tags, and I think that's where my problem came from. For example:  After going through each paragraph break, I managed to get proper formatting back, with colours. My suspicion is that one of my location tags got separated when I was spacing out the text. A simple mistake.", 
            "title": "Transcription"
        }, 
        {
            "location": "/Module_3/#transformations", 
            "text": "In my page5.xml file, the xsl styling is looking for tags like  persName  and  interp . These titles point the browser to the same tag in the .xsl document which defines the style of the .xml file. This uses the same system that web pages utilize, the HTML pointing the browser to the styles defined in the CSS document.   In  SG_transformer.xsl , the browser will be looking at tags such as  ID , or  Repository . I  believe  this uses an elif system, where it defines a list of words as the root of the tag, and each tag would receive a value-of, which might give a tooltip? I'm not 100% on the appearance of the .xml page once these tags are used.   To define different .xsl sheets, you would change the  href  designation on line 2 from:  ?cml-stylesheet type=\"text/xsl\" href=\"000stylesheet.xsl\"?  to  ?cml-stylesheet type=\"text/xsl\" href=\"SG_transformer.xsl\"? . I tried this and didn't get any change in my own .xml file, but I believe that is 1. because I don't have any of the tags and 2. because the  SG_transformer.xsl  file does not have any defined template styles in it. I compared it to the 000style.xsl and the colours and appearance of the tags are defined under the  style  tag throughout the document, which  SG_transformer.xsl  is lacking.   If you want to see the pages, you can view my transcription  here . I also apologize for putting the transformer.xsl file as code, the underscore in it was italicizing large swathes of my text that happened to fall between them.", 
            "title": "Transformations"
        }, 
        {
            "location": "/Module_3/#regex", 
            "text": "After reading the gentle introduction, I can understand how powerful it can be once one knows how to use it. It's a good thing I made a copy. I also need to be careful as to where I leave my cursor when I'm searching. When I leave it at the end, it's hard to find anything in the document after it.   \\r\\n  did not work to find the blank lines. To remove the white spaces, I went into  RegExr's Cheatsheet  and found the Regex for word, which was  \\w , and then used  \\r\\n[^\\w].+  to find all of the white spaces in my document to remove. It successfully worked, however it did leave a few large chunks with blank lines that I can't get RegEx to clear. I suspect that it is because there was more than one line with it, and when I replaced the previous characters with the the empty replace bar, it replaced everything, but maybe put in an invisible character I can't see. I'm not sure yet, still trying. For the sake of my sanity I had to go through and remove each chunk by hand. It wasn't difficult though, as there were only twelve or so of these chunks. I think it's where \"Digitized By Google\" used to sit in the document, and they may have put in something that my text editor can't see/copy. Still not sure.    I find that  RegExr  doesn't seem to process my work properly. I'm not sure why, but I actually find it relatively easy to use Notepad++ as it displays a window at the bottom of the document with all of the information that the find function works. And if something doesn't work, ctrl+Z works magical wonders.   While trying to replace the page number and comma at the end of each index entry, I was getting very bizarre numbers at the end of the entry. Until I realized I had put the space in the wrong spot. When replacing  (, )([0-9]{4})(.+)  with  \\2  I was getting an entry that looked like this:  ~Sam Houston to J. Pinckney Henderson, December 311836 \nThen I realized my misplaced space was in the wrong group, and found that  (,)( [0-9]{4})(.+)  worked significantly better. I proceeded to have a moment of panic when I noticed lines like this:  David G. Bumet, Alc6e La Branche, December 16, 1839 61\nDavid G. Bumet, Alc^ La Branche, December 17, 1839 63 \nBut then upon checking the original document, that is what Google's OCR thought the characters represented.  Something messed up my saves and I managed to save over my step 5 with an earlier version, so I have to backtrack a bit to get back on track, and redo step five and six. In the midst of finding this, I realized I had left the dates at the ends of each entry, so every search would come up with more than three commas in each sentence. So backtrack a little further to step 4. And I managed to fix it with the given Regex. I'm not a hundred percent on what made that occur.", 
            "title": "Regex"
        }, 
        {
            "location": "/Module_3/#open-refine", 
            "text": "Interesting tool. I worked through it all only to find that it left a few entries (possibly worse off). I think its because I might have been trying to add an accented e, but it didn't like it, as a few of my entries have an @ sign in it randomly that wasn't there before. I might try running it through again later, but at least I now know how to basically work the program (which is awesome). Just to play with it, I'm now uploading my .csv into Palladio to see what it comes up with. Data visualization is one of my favourite things!   I don't quite understand it at the moment. Maybe I'll come back to it.", 
            "title": "Open Refine"
        }, 
        {
            "location": "/Module_3/#stanford-ner", 
            "text": "So I'm having significant issues with this one. I can't seem to run the  ner-gui.bat  file to run, it opens a window only to immediately close it again. So following the directions on the end of the Open Refine page, I attempted to run it from the command line in the folder and I'm getting an exception in thread, but I can't figure out what I've done wrong. I have a feeling its something to do with a missing Java definition. I think it's specifically struggling with  edu.stanford.nlp.ie.crf.CRFClassifier     I figured it out. The problem was that I've been trying to run it from command line with the text from the  workbook , which wasn't working. So I tried updating Java, and did that successfully. Still nothing. I was able to successfully open a gui using  stanford-ner.jar , but when I put the text in and selected a classifier, it was not doing anything. So I deleted a large selection of it and finally got my results!   It highlighted my text like it was supposed to. But now the problem remains that I don't have all of the text classified, which I think is going to be a problem in the next exercise. I have a suspicion that the problem is that my computer isn't allocating enough memory, which the Stanford NER page says is a problem:    It might work to double-click on the stanford-ner.jar archive but this may well fail as the operating system does not give Java enough memory for our NER system, so it is safer to instead double click on the ner-gui.bat icon (Windows) or ner-gui.sh (Linux/Unix/MacOSX).   I tried increasing the amount of memory Java gets by default, it did not work either. So now I'm going to try and run only half the file. If that works, I'll save the single file into two files, run each one individually, then amalgamate the two after. I know it doesn't exactly fix my issues long term but it is a working solution.   Success with half the document! I've broken it into two individual files now to run through the NER gui.  Update: \nThe splitting didn't work, it tagged the files but it only highlighted it in the gui. So I went back and edited the  ner-gui.bat  file, adding a  pause  function so I could read what the command file without it auto-quitting, I discovered it was having giving an  unable to allocate space . SO I went into the .bat file and messed around with the  Java -mx  size, and found that it worked successfully, and I could run file through the gui and successfully save a tagged version of the file (which I couldn't do before).   The tagged Texas letters can be found  here .  And the index can be found  here .", 
            "title": "Stanford NER"
        }
    ]
}