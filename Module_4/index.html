<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <meta name="author" content="Reed Haw">
  
  <title>Module 4 - Open Research Notebook</title>
  

  <link rel="shortcut icon" href="../favicon.png">
  

  
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  <link href="../theme_extra.css" rel="stylesheet">

  
  <script>
    // Current page data
    var mkdocs_page_name = "Module 4";
    var mkdocs_page_input_path = "Module_4.md";
    var mkdocs_page_url = "/Module_4/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js"></script>
  <script src="../js/modernizr-2.8.3.min.js"></script>
  <script type="text/javascript" src="../js/highlight.pack.js"></script>
  <script src="../js/theme.js"></script> 

  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> Open Research Notebook</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
        <ul class="current">
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="..">Home</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Module 1</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../hello_world/">Hello world</a>
        
    </li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../markdown_cheetsheet/">Markdown cheetsheet</a>
        
    </li>

        
    </ul>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../Module_2/">Module 2</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../Module_3/">Module 3</a>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 current">
        <a class="current" href="./">Module 4</a>
        
            <ul>
            
                <li class="toctree-l3"><a href="#module-4">Module 4</a></li>
                
                    <li><a class="toctree-l4" href="#seeing-patterns">Seeing Patterns</a></li>
                
                    <li><a class="toctree-l4" href="#exercises">Exercises</a></li>
                
            
            </ul>
        
    </li>
<li>
          
            <li>
    <li class="toctree-l1 ">
        <a class="" href="../Module_5/">Module 5</a>
        
    </li>
<li>
          
            <li>
    <ul class="subnav">
    <li><span>Final Project</span></li>

        
            
    <li class="toctree-l1 ">
        <a class="" href="../Overview/">Overview</a>
        
    </li>

        
    </ul>
<li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">Open Research Notebook</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
    
    <li>Module 4</li>
    <li class="wy-breadcrumbs-aside">
      
        
          <a href="https://github.com/reedhaw/Research-Notebook" class="icon icon-github"> Edit on GitHub</a>
        
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="module-4">Module 4</h1>
<p>4/5/2016 2:34:53 PM </p>
<h3 id="seeing-patterns">Seeing Patterns</h3>
<p>So I'm late, I know. I shouldn't complain about anything, but I am getting the work done, and I do hope *crosses fingers* that I'll be able to get it all done before April 8th. I do like a challenge. The concept of data wrangling is such a cool and important subject. With each new addition to the digital collection of human thought, piles of data are becoming more and more overwhelming. In <a href="https://reedhaw.ca/cms/blog/module-3">module 3</a> we fixed and cleaned up the data from the <a href="http://archive.org/stream/diplomaticcorre33statgoog/diplomaticcorre33statgoog_djvu.txt">Texas Correspondence</a>, and now we're looking at representing this data. </p>
<p>The first thing examined in this module is several projects that work to model data, a very interesting and (relatively new) work that uses history's new macro perspective. For example, in the <a href="http://mappingtexts.stanford.edu/whitepaper/MappingTexts_WhitePaper.pdf">Mapping Texts</a> project, the teams at Stanford University and the University of North Texas worked together to create </p>
<blockquote>
<p>Interactive models that would
experiment with methods for combining text-mining with visualizations, using text-mining to
discover meaningful language patterns in large-scale text collections and then employ
visualizations in order to make sense of them. (<a href="http://mappingtexts.stanford.edu/whitepaper/MappingTexts_WhitePaper.pdf">Mapping Texts, page 6</a>)</p>
</blockquote>
<p>This project, aside from being <em>incredibly cool</em> is also important, as it allows people to visually see represented information that has been mined from a text. It's not necessarily a first, but to be able to see how many times Dallas appears in the newspapers, and to see that represented larger on a map of Texas. The analysis of large data sets is such a useful tool. And when the OCR text is accurate (which appears to have been a problem for the teams as well, as they addressed it in their document), it allows for a more accurate and faster analysis of the documents. The usefulness of this is not lost on me. To be able to look at a body of texts and to identify and place the areas that they mention is incredible, as it gives people an easier way to recognize data. </p>
<p>The next piece examined is the blog post <a href="http://historyinthecity.blogspot.ca/2013/12/corpus-linguistics-for-historians.html">Corpus Lingustics for Historians</a> discusses the computer analysis of relationships between words, which I <em>believe</em> allows computers to find the general context of certain words and phrases throughout a body of works, and can give a general impression of themes. This can effectively allow someone to analyze the use of words, density, placement, and other correlations that I might not even be able to think about yet! In <a href="http://historyinthecity.blogspot.ca/2013/12/visualizing-gender-in-history-of-woman.html">Visualizing Gender in History of Woman Suffrage</a>, Michelle Moravec creates correlations that examine the <em>feelings</em> towards certain words, such as that of <strong>my husband</strong> which appears in mostly negative terms. These correlations that reveal information that would otherwise require a human to read through and make the correlations themselves (which would be significantly more difficult and full of errors) is just amazing. </p>
<p><strong>Return to the podcast</strong> </p>
<p>Network analysis on <a href="http://www.scottbot.net/HIAL/index.html@tag=network-analysis.html">scottbot.net</a> gives several examples of network examples and metrics and bimodality. I've read some of it, and honestly don't entirely understand what network analysis is outside of connecting related objects and analyzing said connections. Topic modelling is also another beautiful way to display information and (hehe) networking (is that right?). Topic modelling allows connections people might not have noticed before become apparent, and shows the relative values of it. </p>
<h2 id="exercises">Exercises</h2>
<h3 id="gephi">Gephi</h3>
<p>So upon opening Gephi, the first thing I did was attempt to import the .csv file from the previous exercise. I did as the instruction said, but was getting the error that there were empty columns. So I had to open up the csv file and find what the one blank cell that happened to be causing me troubles. I managed to find it though. I'm noticing however, that every column has a weight of 1, which is incorrect. They should be dependent on how many letters are sent by the same people. I've also noticed that I have slightly more edges than I'm supposed to (approximately 588 more). I'm not sure what happened, but I think that my csv sheet has been majorly screwed up and I'm not a hundred percent sure why, as everything appears as it should. </p>
<p>So in an attempt to clear things up I ran it through open refine again and fixed some of the stranger characters, still nothing. I set a column to specify an undirected network which Gephi liked - at first. I entered the data again and ran the Connected Components algorithm and got the appropriate results, but I still haven't gotten the appropriate number of edges or a differing weight value. Moving on from that, when I run PageRank I find another difficulty. I'm supposed to specify a directed network now, which is something I can't do because of specifying it as directed in the csv sheet. And there appears to be no way to remove the column, so I'm again going to have to re-add the sheet. </p>
<p>Luckily adding the same sheet again and again makes a lot of the instructions pretty easy to replicate. A few minutes later I'm back to where I was when I started. Everything has worked out from this point. In the ranking area I had a slight difficulty, the instructions differed, I could not find a 'ranking' tab or a red diamond. So I used the size selection and used PageRank to adjust the sizes, which worked just the same (I hope). </p>
<p>Upon previewing it, I found that my network was weirdly sideways? To put it plainly. The <a href="http://workbook.craftingdigitalhistory.ca/supporting%20materials/gephi.txt/">workbook</a> says that the communities should be upper and lower, which mine seem to be more of a left-right distribution, but I suppose it still represents the information in a relatively similar form. The two communities are still similarly discernable (although I think there could be a way to distribute it better and represent the information easier). To get the weight working would probably be relatively useful. However, the distribution is still interesting to see, such as how Ashbel Smith and Anson Jones dominate the community, as it was likely during the time of Anson Jones that the letters were documented. Chances are that Sam Houston, who barely appears in the network, his letters were either lost, or not accounted for as he was no longer president and was not sending official correspondence. </p>
<p>Then I broke my upload notebook by trying to rename it from reedhaw.github.io to dighital-history. I need to stop messing around with what's working. But now it's back up and running.</p>
<h3 id="topic-modelling">Topic Modelling</h3>
<p>This was relatively straightforward. I had no hiccups (surprisingly, as my machine can never seem to just <em>do</em> something as expected). I can see and understand how the topic modelling <em>might</em> be useful, but I'm not a hundred percent on how it exactly helps. I see a list of topics, but the "topics" are just a line of random words that seem to have a similar meaning. ship letter board kingdom arrived young extract captain dated passenger doesn't mean a whole lot to me, but by using it to find the selection of words in each of the documents. I can understand how one would use it to view distribution of words throughout docs, and to easily see correlations between docs. My interpretation of this program is that it best estimates what the topic of each of the document is, and generates a list to show you the number of times the words appear in each document. Or along those lines. By importing the csvs into a network modelling program, you could create visual correlations of specific word usage in each document, or something along those lines. </p>
<p>Going further, I ran my files from the Canadiana API and the topics all came up as html work (text, type, cookie, script, meta, body, etc.). I'm not actually a hundred percent certain I ran the right files but that's what I got!</p>
<h3 id="topic-modelling-in-r">Topic Modelling in R</h3>
<p>I absolutely love the style of <a href="http://tryr.codeschool.com/">codeschool.com</a>. It also lays out everything in pretty straightforward terms. I completed all seven chapters of the Code School tutorial. </p>
<p><img alt="I made it!" src="http://d1kbt5mjomv40p.cloudfront.net/assets/badge-7-large-14d7ef569494983ca19b444a65c4ddb6.png" /></p>
<p>So moving onto the next stage, I am faced with RStudio, and the first problem I run into is that I can't load the rJava library. So I'm scrolling through forums and I find people talking about adding the Java location to my <code>PATH</code> variable, which I do. No success. The next thing I find is that I need R and Java to run on the same architecture (64 bit in my case), which I discovered I was using the Java Development Kit in 32 bit in the most modern update, and 64 bit in a slightly older version. I am currently attempting to update to see if that resolves my problem. This solved my problem. </p>
<p>Following the tutorial, I had no problems with this, and it all went smoothly. Check my <a href="https://github.com/reedhaw/Digital-History/tree/master/Beals">GitHub repository</a> for my script of this (among other things). </p>
<h3 id="text-analysis-with-overview">Text Analysis with Overview</h3>
<p>Overview makes a ton of sense to me, and is an analysis program that makes sense. Uploading the CND.csv however did not give me an option to choose words. The use of systems similar to this is incredibly interesting, as it allows for an unparalleled examination of keywords and allows for rapid navigation of large text bodies. It is actually very similar to the topic modelling software used in exercise two. </p>
<h3 id="antconc">AntConc</h3>
<p>Working with AntConc is an incredible piece of software for analysis (much like the former few) but I feel that these features are ones that I can truly relate to, and something that I could use in my own research to identify both the context and the specific information provided. </p>
<p>In entering the data from the CND Dataset, I had to first split the file. After a few seconds of browsing Google I found a tool called CSV splitter, a program that did exactly what its name denotes. After setting the parameters to one row per file, I suddenly see 357 new files in my folder, which is exactly what I wanted (for once). And I immediately spoke too soon. They were all exported as csv when I need tab deliminated files instead. Achieved this by using command prompt and running this code: <code>ren
 *.csv *.txt</code>. It worked perfectly, and although it might not quite be the proper way to go about it, it certainly worked for my purposes. These split files were successfully opened in AntConc!</p>
<h3 id="text-analysis-with-voyant">Text Analysis with Voyant</h3>
<p>What an interesting tool. The very act of uploading the corpus in chronological order changes the data representation significantly. It goes from most common words of "the, and, by , to, of" to "new, mr, country, government, great". This shift (and the increase in colours) gives a better representation of what is displayed. And I just found out the hard way that markdown pad does NOT like when really long HTML code is thrown into it. <em>looking at you Voyant Tools HTML 'snippet'</em>. By applying stop words I see (in the original unordered list) the words I took note of before disappear, and are now showing em "united, scotland, kingdom, mr" etc. Removing stop words is essential (and essential to have an accurate list) as they will skew word results and data that could be unimportant (such as titles, headers, metadata). </p>
<h3 id="quick-charts-using-raw">Quick Charts Using RAW</h3>
<p>The only problem I've had thus far with RAW had nothing to do with it, rather it was the problem with the spreadsheet, the blank detector simply did not want to cooperate, but I worked away until it agreed to do what I wanted. So far, what I can say about RAW is that it is beautifully designed.</p>
<p>Upon placing Place 1 and Place 2 into the system, Texas and Mexico immediately popped out as the largest places documentation went to. Place 3 and Place 4 immediately appear the same way. In the second set, there appeared to be a significant amount of correspondence being sent to the same place, whereas the first set the correspondence seemed relatively mixed. </p>
<h3 id="georectifying">Georectifying</h3>
<p><a href="http://warp.worldmap.harvard.edu/maps/tile/5507/z/x/y.png">Google tiles warped map</a> A relatively straight forward exercise, I found it easiest to line the control points up with that of streets, and attempt at some geographic features. The biggest problem was that the map I happened to pick turned out to have a large cut out in the middle, displaying what appeared to be a different area that did not quite line up with that of Buckingham, Quebec. Took me a while to finally find the small town of Buckingham, Quebec. But I finally did it and it successfully uploaded to Palladio with no troubles. </p>
<h3 id="text-analysis-with-r">Text Analysis with R</h3>
<p>I thing that I might have removed a little too much in this exercise, as the plots give two words now, "will" and "idglasgow" in the word cloud. So something has gone wrong, and I'm not entirely sure of what yet, but I will attempt to rectify this later (as I am now in quite the time crunch). </p>
<p>For exercise 10, both github links don't seem to work, and displayed a 404 error. So I'm going to go ahead and move on to Module 5. </p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../Module_5/" class="btn btn-neutral float-right" title="Module 5">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../Module_3/" class="btn btn-neutral" title="Module 3"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
      <p>Copyright Â© 2016 Reed Haw</p>
    
  </div>

  Built with <a href="http://www.mkdocs.org">MkDocs</a> using a <a href="https://github.com/snide/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
</footer>
	  
        </div>
      </div>

    </section>

  </div>

<div class="rst-versions" role="note" style="cursor: pointer">
    <span class="rst-current-version" data-toggle="rst-current-version">
      
          <a href="https://github.com/reedhaw/Research-Notebook" class="icon icon-github" style="float: left; color: #fcfcfc"> GitHub</a>
      
      
        <span><a href="../Module_3/" style="color: #fcfcfc;">&laquo; Previous</a></span>
      
      
        <span style="margin-left: 15px"><a href="../Module_5/" style="color: #fcfcfc">Next &raquo;</a></span>
      
    </span>
</div>

</body>
</html>
